{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ECE495 In-class Exercise 6: Spiking data\n",
    "_Due 4/9 by start of class 0830_  \n",
    "_4/9 class will be a Final Project workday - no work on this ICE!!_  \n",
    "\n",
    "In this exercise, you will:\n",
    "- Build an AER to create a spiking video\n",
    "- Run said AER through Nengo neurons\n",
    "\n",
    "The main concept of this exercise is:\n",
    "- To understand the format of event-based data and how it is used\n",
    "\n",
    "Why??\n",
    "- To create extremely low power systems by collecting spiking data and processing on the spikes directly using spikes\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up\n",
    "\n",
    "**Ensure you are using your [495 Virtual Environment](https://github.com/kaitlin-fair/495venv_setup) before you begin (`nengo-loihi` installed)!**  \n",
    "    \n",
    "Then, import Nengo, NengoLoihi, and other supporting libraries into your program to get started:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.6' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/C25Hana.Hill/.pyenv/pyenv-win/versions/3.9.6/python.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML\n",
    "from matplotlib.animation import ArtistAnimation\n",
    "\n",
    "import nengo\n",
    "import nengo_loihi\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build your spiking data (i.e. your AER)\n",
    "\n",
    "Your goal is to create an interesting spiking video with a *.csv file just like `ILAN City Frame Data.csv` OR with an event array (therefore bypassing the need for this line of code: `events = csv_to_event_array(csv_filename, start_time, end_time)`). _Most interesting video gets a prize_ - have fun with this!\n",
    "\n",
    "**.csv file**\n",
    "\n",
    "Take a look at the `ILAN City Frame Data.csv` file. You will see in that file that you have x- and y-coordinates at which an event took place, a polarity of said event, and the time of said event. I would recommend creating a video consisting of square images sized 100x100 pixels. If you would like for your video to have both positive and negative spiking events, use polarities of 1 and 0, respectively. \n",
    "\n",
    "**events_array**\n",
    "\n",
    "The events array contains a list for every event consisting of the following values:   \n",
    "- `y`: The vertical coordinate of the event.\n",
    "- `x`: The horizontal coordinate of the event.\n",
    "- `p`: The polarity of the event (0 for off, 1 for on).\n",
    "- `v`: The event trigger (0 for camera events, 1 for external events). In our case, these will all be 0.\n",
    "- `t`: The event timestamp _in microseconds_. \n",
    "\n",
    "You can see the format of this list - `[(y, x, p, v, t)]` for each event - within the `csv_to_event_array` function. You then fill the final `events_array` with `np.array(events_list, dtype=[('x', 'i4'), ('y', 'i4'), ('p', 'i4'), ('t', 'i4'), ('v', 'i4')])`. \n",
    "\n",
    "**Notes**\n",
    "\n",
    "The next block of code is still built to read in a particular *.csv file. You will need to determine what to comment out / change to use the data you generate on your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.6' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/C25Hana.Hill/.pyenv/pyenv-win/versions/3.9.6/python.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# LtCol Jurado's Python wizardry\n",
    "def csv_to_event_array(csv_filename: str, start_frame: int, end_frame: int) -> np.ndarray:\n",
    "    # ======= DVS camera - Physics dept ===========\n",
    "    df = pd.read_csv(csv_filename, names=['x', 'y', 'p', 't'])\n",
    "    \n",
    "    df['v'] = np.zeros(len(df), dtype=int)\n",
    "    sub_df = df[(start_frame <= df['t']) & (df['t'] <= end_frame)]\n",
    "\n",
    "    sub_df['t'] = sub_df['t'] - sub_df['t'].iloc[0]\n",
    "\n",
    "    events_list = [(y, x, p, v, t) for x, y, p, t, v in sub_df.values]\n",
    "    events_array = np.array(events_list, dtype=[('y', 'i4'), ('x', 'i4'), ('p', 'i4'), ('v', 'i4'), ('t', 'i4')])\n",
    "\n",
    "    return events_array\n",
    "\n",
    "# the csv file we will convert and the time range of our events\n",
    "\n",
    "# ======= DVS camera - Physics dept ===========\n",
    "csv_filename = 'Hana_ice6.csv'\n",
    "start_time = 1000\n",
    "end_time = 500000\n",
    "# =============================================\n",
    "\n",
    "# use the fancy function to turn this into the format Nengo likes\n",
    "events = csv_to_event_array(csv_filename, start_time, end_time)\n",
    "dvs_events = nengo_loihi.dvs.DVSEvents()\n",
    "# this is really where the conversion happens\n",
    "dvs_events.init_events(event_data=events)\n",
    "\n",
    "# Save it as a *.events file!\n",
    "events_file_name = \"dvs-from-file-events.events\"\n",
    "dvs_events.write_file(events_file_name)\n",
    "print(\"Wrote %r\" % events_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View the data (NOT using neurons yet)\n",
    "\n",
    "You will need to adjust some of the parameters in this block of code, such as image size and time steps. \n",
    "\n",
    "Note that once you've written an events file using `dvs_events` that you're good with, you can comment out the last block to save some time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dvs_events = nengo_loihi.dvs.DVSEvents.from_file(events_file_name)\n",
    "\n",
    "# ======= DVS camera - Physics dept ===========\n",
    "img_height = 100\n",
    "img_width = 100\n",
    "t_length_us = end_time - start_time #value is in microseconds\n",
    "t_length_s = t_length_us * 1e-6 #convert prior value to seconds\n",
    "dt_frame_us = (10 * 1e-3) * 1e6 #this value is also in microseconds\n",
    "t_frames = dt_frame_us * np.arange(int(round(t_length_us / dt_frame_us))) #number of frames in video\n",
    "# =============================================\n",
    "\n",
    "fig = plt.figure()\n",
    "imgs = []\n",
    "for t_frame in t_frames:\n",
    "    t0_us = t_frame\n",
    "    t1_us = t0_us + dt_frame_us\n",
    "    t = dvs_events.events[:][\"t\"]\n",
    "    m = (t >= t0_us) & (t < t1_us)\n",
    "    events_m = dvs_events.events[m]\n",
    "\n",
    "    # Empty frame\n",
    "    frame_img = np.zeros((img_height, img_width))\n",
    "\n",
    "    for sub_event in events_m:\n",
    "        # show \"off\" (0) events as -1 and \"on\" (1) events as +1\n",
    "        event_sign = 2.0 * sub_event[\"p\"] - 1\n",
    "        frame_img[sub_event[\"y\"], sub_event[\"x\"]] = frame_img[sub_event[\"y\"], sub_event[\"x\"]] + event_sign\n",
    "    \n",
    "    img = plt.imshow(frame_img[:, ::-1], animated=True)\n",
    "    imgs.append([img])\n",
    "\n",
    "ani = ArtistAnimation(fig, imgs, interval=50, blit=True)\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build your model\n",
    "\n",
    "You will likely need to adjust your `pool` size depending on the dimensions of your video and your `sim_time` based on the duration of your video.\n",
    "\n",
    "You can read about `nengo_loihi.dvs.DVSFileChipProcess` [here](https://www.nengo.ai/nengo-loihi/api.html#dvs).\n",
    "- `file_path`:The path of the file to read from. Can be a .aedat or .events file. Format of the file will be detected from the file extension.\n",
    "- `pool`: Number of pixels to pool over in the vertical and horizontal directions, respectively. The larger the pool, the fewer neurons required.\n",
    "- `channels_last`: Whether to make the channels (i.e. the polarity) the least-significant index (True) or the most-significant index (False).\n",
    "\n",
    "To read about how to use enumerate in loop, look [here](https://www.geeksforgeeks.org/enumerate-in-python/). This will be useful for connecting arrays of neuron ensembles in your final project as it eliminates the need for indexing inside of a loop. You instead just call the second argument (in this example: `e`). \n",
    "\n",
    "`dvs_process.polarity` is the number of polarity values in the data. In this case we have 2: one for positive events, one for negative. The `::` is called a \"stride\" and can be used to skip through an array by a certain amount. In this case, we start at the $k^{th}$ value (0 or 1) and stride by 2. You can find some easier examples [here](https://scipython.com/book/chapter-2-the-core-python-language-i/examples/string-striding/).\n",
    "\n",
    "Otherwise - this should all look familiar!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======= DVS camera - Physics dept ===========\n",
    "pool = (2, 2)\n",
    "\n",
    "model = nengo.Network(label=\"Spiking Data\")\n",
    "with model:\n",
    "    dvs_process = nengo_loihi.dvs.DVSFileChipProcess(\n",
    "        file_path=events_file_name, pool=pool, channels_last=True,\n",
    "        dvs_height=img_height, dvs_width=img_width\n",
    "    )\n",
    "    u = nengo.Node(dvs_process)\n",
    "\n",
    "    ensembles = [\n",
    "        nengo.Ensemble(\n",
    "            dvs_process.height * dvs_process.width,\n",
    "            1)\n",
    "        for _ in range(dvs_process.polarity)\n",
    "    ]\n",
    "\n",
    "    for k, e in enumerate(ensembles):\n",
    "        u_channel = u[k :: dvs_process.polarity]\n",
    "        nengo.Connection(u_channel, e.neurons, transform=1.0 / np.prod(pool))\n",
    "\n",
    "    probes = [nengo.Probe(e.neurons) for e in ensembles]\n",
    "\n",
    "with nengo.Simulator(model) as sim:\n",
    "    sim.run(t_length_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View the data (using Nengo neurons!)\n",
    "\n",
    "This looks very much the same as viewing the data with regular Python - except now we are reading spikes from our probed neurons!\n",
    "\n",
    "This section should not require any edits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_t = sim.trange()\n",
    "shape = (len(sim_t), dvs_process.height, dvs_process.width)\n",
    "output_spikes_neg = sim.data[probes[0]].reshape(shape) * sim.dt\n",
    "output_spikes_pos = sim.data[probes[1]].reshape(shape) * sim.dt\n",
    "\n",
    "dt_frame = dt_frame_us * 1e-6 # this is in seconds\n",
    "dt_frame_us = (10 * 1e-3) * 1e6 #this value is in microseconds\n",
    "t_frames = dt_frame * np.arange(int(round(t_length_s / dt_frame)))\n",
    "\n",
    "fig = plt.figure()\n",
    "imgs = []\n",
    "for t_frame in t_frames:\n",
    "    t0 = t_frame\n",
    "    t1 = t_frame + dt_frame\n",
    "    m = (sim_t >= t0) & (sim_t < t1)\n",
    "\n",
    "    frame_img = np.zeros((dvs_process.height, dvs_process.width))\n",
    "    frame_img -= output_spikes_neg[m].sum(axis=0)\n",
    "    frame_img += output_spikes_pos[m].sum(axis=0)\n",
    "    frame_img = frame_img / np.abs(frame_img).max()\n",
    "\n",
    "    img = plt.imshow(frame_img[:, ::-1], vmin=-1, vmax=1, animated=True)\n",
    "    imgs.append([img])\n",
    "\n",
    "ani = ArtistAnimation(fig, imgs, interval=50, blit=True)\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion - fill in an answer within the next markdown block\n",
    "\n",
    "(1) Given the video you build, what is some data processing we could perform _within Nengo neurons_ on your data?\n",
    "\n",
    "(2) Why would we want to do that?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Using nengo we could multiply all values by 100 then pool these values to get a more clear picutre. We could also add more neurons for clarity. \n",
    "2) We would want to do this to get a more defined picture resolution. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.10-nengo3.2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
